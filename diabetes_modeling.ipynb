# ==========================================
# Diabetes Predictive Modeling
# ==========================================

# Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

# Set plot style
sns.set_style("whitegrid")

# ------------------------------------------
# 1. Load Dataset
# ------------------------------------------
url = 'https://raw.githubusercontent.com/andrewtran-data/diabetes-analysis/main/data/diabetes.csv'
data = pd.read_csv(url)

# Show first 5 rows
print("First 5 rows:")
print(data.head())

# Show summary statistics
print("\nSummary statistics:")
print(data.describe())

# Check for zero values in important columns
cols = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']
for col in cols:
    zeros = (data[col] == 0).sum()
    print(f"{col}: {zeros} zero values")

# ------------------------------------------
# 2. Exploratory Visualization (Optional)
# ------------------------------------------

# BMI distribution
plt.figure(figsize=(8,5))
sns.histplot(data['BMI'], bins=30, kde=True)
plt.title('BMI Distribution')
plt.xlabel('BMI')
plt.ylabel('Frequency')
plt.show()

# Glucose levels by Outcome
plt.figure(figsize=(8,5))
sns.boxplot(x='Outcome', y='Glucose', data=data)
plt.title('Glucose Levels by Diabetes Outcome')
plt.xlabel('Outcome (0 = No, 1 = Yes)')
plt.ylabel('Glucose')
plt.show()

# Correlation heatmap
plt.figure(figsize=(10,8))
sns.heatmap(data.corr(), annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.show()

# Average values by Outcome
print("\nAverage values by Outcome:")
print(data.groupby('Outcome').mean())

# ------------------------------------------
# 3. Prepare Data for Modeling
# ------------------------------------------

# Features and target
X = data.drop('Outcome', axis=1)
y = data['Outcome']

# Train/Test split (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Feature scaling for Logistic Regression
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# ------------------------------------------
# 4. Logistic Regression
# ------------------------------------------
lr = LogisticRegression(random_state=42)
lr.fit(X_train_scaled, y_train)
y_pred_lr = lr.predict(X_test_scaled)

print("\nLogistic Regression Metrics:")
print("Accuracy:", accuracy_score(y_test, y_pred_lr))
print("Precision:", precision_score(y_test, y_pred_lr))
print("Recall:", recall_score(y_test, y_pred_lr))
print("F1-score:", f1_score(y_test, y_pred_lr))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_lr))

# ------------------------------------------
# 5. Random Forest
# ------------------------------------------
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)

print("\nRandom Forest Metrics:")
print("Accuracy:", accuracy_score(y_test, y_pred_rf))
print("Precision:", precision_score(y_test, y_pred_rf))
print("Recall:", recall_score(y_test, y_pred_rf))
print("F1-score:", f1_score(y_test, y_pred_rf))

# ------------------------------------------
# 6. XGBoost
# ------------------------------------------
xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
xgb.fit(X_train, y_train)
y_pred_xgb = xgb.predict(X_test)

print("\nXGBoost Metrics:")
print("Accuracy:", accuracy_score(y_test, y_pred_xgb))
print("Precision:", precision_score(y_test, y_pred_xgb))
print("Recall:", recall_score(y_test, y_pred_xgb))
print("F1-score:", f1_score(y_test, y_pred_xgb))

# ------------------------------------------
# 7. Compare F1-scores
# ------------------------------------------
models = ['Logistic Regression', 'Random Forest', 'XGBoost']
f1_scores = [
    f1_score(y_test, y_pred_lr),
    f1_score(y_test, y_pred_rf),
    f1_score(y_test, y_pred_xgb)
]

plt.figure(figsize=(8,5))
sns.barplot(x=models, y=f1_scores)
plt.title('F1-score Comparison')
plt.ylabel('F1-score')
plt.ylim(0,1)
plt.show()
